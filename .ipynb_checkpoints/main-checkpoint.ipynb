{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca3a95-87a8-4165-ab2e-62b260263322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6611ba2-5f4c-4f36-9b06-16ebdeae986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"AmesHousing_before.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c243b35a-b4a6-4b0f-8ca5-930283d3e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e58723-19b5-467f-857b-d675ab05d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb4e82-8608-4b8e-ad76-a9be2d751672",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"Pool QC\",\"Fence\",\"Alley\",\"Misc Feature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8629d-11e3-4b15-9a07-7c3db244f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.select_dtypes(include=\"object\").columns: #only object for now because only ones that need \"None\" in string\n",
    "    mode_val = data[col].mode()[0] #Find the most common value\n",
    "    data[col] = data[col].fillna(mode_val if data[col].value_counts()[mode_val] > 100 else \"None\") #If that value appears a lot (100+), use it to fill in blanks. Otherwise, just say 'None' because it's probably missing for a reason. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a747e5-55d2-4c49-a0f0-c92d667565b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_fill_cols = [\n",
    "    'Garage Yr Blt', 'Garage Area', 'Garage Cars',\n",
    "    'Mas Vnr Area', 'BsmtFin SF 1', 'BsmtFin SF 2',\n",
    "    'Bsmt Unf SF', 'Total Bsmt SF', 'Bsmt Full Bath', 'Bsmt Half Bath'\n",
    "]\n",
    "\n",
    "for col in zeros_fill_cols:\n",
    "    data[col] = data[col].fillna(0)\n",
    "\n",
    "# Separate for Lot frontage (estimate), random missing size\n",
    "data['Lot Frontage'] = data['Lot Frontage'].fillna(data['Lot Frontage'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb5150-93d6-42ae-b9f8-95d5b26f6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = [\"Order\", \"PID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662dfcb-2227-44e1-b018-f16c4e5efc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA): Understand the data before modeling\n",
    "#cleaned_data = X_train.join(y_train) # Just indexing the column to the right of X_train (since it was removed from X_train)\n",
    "cleaned_data = data.copy()\n",
    "cleaned_data.hist(figsize=(20,15)) # Creates histograms for each numerical column in cleaned_data\n",
    "# Did cleaned_data.hist() first, but need to arrange visually how it looks so I added plot size with figsize = (width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc168c-7f60-4166-8eda-42e800911554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target variable\n",
    "cleaned_data.select_dtypes(include=\"number\").corr() # Computes Pearson correlation between every pair of numerical columns. Values range from +1 (as one goes up, so does the other), 0 (no correlation), -1 (as one goes up, the other goes down)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c2e43e-e97f-41ea-ba21-0a16a9dec59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(30,25)) # rule of thumb: figsize = (num_columns * 1, num_columns * 0.5)\n",
    "sns.heatmap(cleaned_data.select_dtypes(include=\"number\").corr(),annot=True, cmap=\"YlGnBu\") # Heatmap, annot=True = aka we're going to see the correlation number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351435fe-3669-4c32-aa60-377f9a7d98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding  \n",
    "cleaned_data['House Age'] = cleaned_data['Yr Sold'] - cleaned_data['Year Built'] \n",
    "cleaned_data['Since Remod'] = cleaned_data['Yr Sold'] - cleaned_data['Year Remod/Add']\n",
    "#By doing the line below, we see there's an error in hour dataset (house sold before it's built) so we drop that row\n",
    "#cleaned_data[cleaned_data['House Age'] < 0][['Yr Sold', 'Year Built', 'Age']]\n",
    "cleaned_data = cleaned_data[(cleaned_data['House Age'] >= 0) & (cleaned_data['Since Remod'] >= 0)].copy()\n",
    "cleaned_data['Was Remod'] = (cleaned_data['Year Built'] != cleaned_data['Year Remod/Add']).astype(int)\n",
    "\n",
    "cleaned_data['HAS Garage'] = (cleaned_data['Garage Area'] > 0).astype(int)\n",
    "# First set Garage Yr Blt = NaN for houses with no garage\n",
    "cleaned_data.loc[cleaned_data['HAS Garage'] == 0, 'Garage Yr Blt'] = np.nan\n",
    "cleaned_data['Garage Age'] = (cleaned_data['Yr Sold'] - cleaned_data['Garage Yr Blt']).fillna(-1)\n",
    "cleaned_data['Garage Yr Blt'] = cleaned_data['Garage Yr Blt'].fillna(-1)\n",
    "\n",
    "# 1. Grab all numerical columns from your cleaned_data\n",
    "num_features = cleaned_data.select_dtypes(include='number').columns\n",
    "\n",
    "# 2. Melt the dataframe to long format for FacetGrid\n",
    "melted = pd.melt(cleaned_data, value_vars=sorted(num_features))\n",
    "\n",
    "# 3. Plot with FacetGrid and histplot\n",
    "g = sns.FacetGrid(melted, col='variable', col_wrap=4, sharex=False, sharey=False, height=3)\n",
    "g.map(sns.histplot, 'value', kde=True, bins=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e229896c-68b7-4d7c-bacb-b7d2e22a4145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transformation for skewed columns\n",
    "cleaned_data['SalePrice'] = np.log(cleaned_data['SalePrice'] + 1)\n",
    "cleaned_data['Lot Frontage'] = np.log(cleaned_data['Lot Frontage'] + 1)\n",
    "cleaned_data['Lot Area'] = np.log(cleaned_data['Lot Area'] + 1)\n",
    "cleaned_data['1st Flr SF'] = np.log(cleaned_data['1st Flr SF'] + 1)\n",
    "cleaned_data['Gr Liv Area'] = np.log(cleaned_data['Gr Liv Area'] + 1)\n",
    "\n",
    "#cleaned_data['Bsmt Unf SF'] = np.log(cleaned_data['Bsmt Unf SF'] + 1)\n",
    "cleaned_data['HAS Bsmt Unf'] = (cleaned_data['Bsmt Unf SF'] > 0).astype(int)\n",
    "\n",
    "cleaned_data['Total Bsmt SF'] = np.log(cleaned_data['Total Bsmt SF'] + 1)\n",
    "\n",
    "# fix the MS SubClass that's a categorical feature:\n",
    "cleaned_data['MS SubClass'] = cleaned_data['MS SubClass'].astype(str)\n",
    "\n",
    "# clean up some dataset features:\n",
    "cleaned_data['HAS Enclosed Porch'] = (cleaned_data['Enclosed Porch'] > 0).astype(int)\n",
    "cleaned_data['HAS 3Ssn Porch'] = (cleaned_data['3Ssn Porch'] > 0).astype(int)\n",
    "cleaned_data['HAS Screen Porch'] = (cleaned_data['Screen Porch'] > 0).astype(int)\n",
    "cleaned_data['HAS Open Porch SF'] = (cleaned_data['Open Porch SF'] > 0).astype(int)\n",
    "cleaned_data['HAS Wood Deck SF'] = (cleaned_data['Wood Deck SF'] > 0).astype(int)\n",
    "cleaned_data['HAS Pool Area'] = (cleaned_data['Pool Area'] > 0).astype(int)\n",
    "cleaned_data['HAS Misc Val'] = (cleaned_data['Misc Val'] > 0).astype(int)\n",
    "cleaned_data['HAS Mas Vnr'] = (cleaned_data['Mas Vnr Area'] > 0).astype(int)\n",
    "\n",
    "\n",
    "cleaned_data['HAS BsmtFin 1'] = (cleaned_data['BsmtFin SF 1'] > 0).astype(int)\n",
    "cleaned_data['HAS BsmtFin 2'] = (cleaned_data['BsmtFin SF 2'] > 0).astype(int)\n",
    "cleaned_data['HAS 2nd Flr'] = (cleaned_data['2nd Flr SF'] > 0).astype(int)\n",
    "cleaned_data['HAS Low Qual Fin'] = (cleaned_data['Low Qual Fin SF'] > 0).astype(int)\n",
    "cleaned_data['HAS Bsmt Full Bath'] = (cleaned_data['Bsmt Full Bath'] > 0).astype(int)\n",
    "cleaned_data['HAS Bsmt Half Bath'] = (cleaned_data['Bsmt Half Bath'] > 0).astype(int)\n",
    "\n",
    "# one-hot encode categorical columns\n",
    "categorical_cols = cleaned_data.select_dtypes(include = 'object').columns\n",
    "cleaned_data = pd.get_dummies(cleaned_data, columns = categorical_cols, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b91fbb-4627-4018-9f99-1cdd9e48474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Grab all numerical columns from your cleaned_data\n",
    "num_features = cleaned_data.select_dtypes(include='number').columns\n",
    "\n",
    "# 2. Melt the dataframe to long format for FacetGrid\n",
    "melted = pd.melt(cleaned_data, value_vars=sorted(num_features))\n",
    "\n",
    "# 3. Plot with FacetGrid and histplot\n",
    "g = sns.FacetGrid(melted, col='variable', col_wrap=4, sharex=False, sharey=False, height=3)\n",
    "g.map(sns.histplot, 'value', kde=True, bins=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68298904-6396-4649-88d9-a7aea17a79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "cleaned_data.head()\n",
    "cleaned_data.to_csv(\"preprocessed_data.csv\", index=False)\n",
    "# Calculate skewness of numeric features\n",
    "skew_values = cleaned_data.select_dtypes(include='number').skew()\n",
    "\n",
    "# Sort by absolute skew (most skewed features first)\n",
    "skew_sorted = skew_values.sort_values(ascending=False)\n",
    "\n",
    "# Show top skewed features\n",
    "print(skew_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6b362-c71e-404e-97ea-a32551b11804",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.melt(cleaned_data, id_vars=['SalePrice'], value_vars=sorted(num_features))\n",
    "g = sns.FacetGrid(f, col='variable', col_wrap=4, sharex=False, sharey=False)\n",
    "g = g.map(sns.regplot, 'value', 'SalePrice', scatter_kws={'alpha':0.3})\n",
    "[plt.setp(ax.get_xticklabels(), rotation=60) for ax in g.axes.flat]\n",
    "g.fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = cleaned_data.drop(columns=['SalePrice'])\n",
    "y = cleaned_data['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a7d09-bf53-4dd7-b56e-f1755d1125d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for selecting our model:\n",
    "from sklearn.linear_model import LinearRegression # use Linear Regression model from scikit=learn\n",
    "from sklearn.metrics import mean_squared_error, r2_score # we got tools to check how good the model is, after making predictions\n",
    "#starting with linear first\n",
    "\n",
    "# 1. Train the model\n",
    "lr_model = LinearRegression() # creates an empty Line Regression model, not trained\n",
    "lr_model.fit(X_train, y_train) # we train the model using training data (X_train and y_train) (model learns the pattern and tries to find the best line that fits the data\n",
    "\n",
    "# 2. Predict\n",
    "y_pred = lr_model.predict(X_test) # use the trained model to make predicitons on the new data (X_test) to get an estimate of what the y values should be\n",
    "\n",
    "# 3. Evaluate\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred)) # we compare the model's predicitons (y_pred) with the actual values (y_test) to calculate the Root Mean Squared Error (RMSE) the smaller it is the better \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"RÂ²:\", r2)\n",
    "\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.xlabel(\"Actual SalePrice\")\n",
    "plt.ylabel(\"Predicted SalePrice\")\n",
    "plt.title(\"Actual vs. Predicted SalePrice\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')  # perfect prediction line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b56085-b686-45f8-9c41-3663d79bb087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model\n",
    "joblib.dump(lr_model, \"linear_model.pkl\")\n",
    "\n",
    "# Save the list of columns your model expects\n",
    "joblib.dump(X_train.columns.tolist(), \"model_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badace2e-e031-4f74-a509-7077dddd62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load model and expected features\n",
    "model = joblib.load(\"linear_model.pkl\")\n",
    "columns = joblib.load(\"model_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b9451-2c17-44ca-b132-b73f1fc6e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your manually set values\n",
    "custom_values = {\n",
    "    'Gr Liv Area': 1500,\n",
    "    'Garage Cars': 2,\n",
    "    'Overall Qual': 6,\n",
    "    'Year Built': 2003,\n",
    "}\n",
    "\n",
    "# Create the full row with default 0s\n",
    "input_data = pd.DataFrame([0] * len(columns), index=columns).T\n",
    "\n",
    "# Fill in your custom values\n",
    "for key, val in custom_values.items():\n",
    "    if key in input_data.columns:\n",
    "        input_data.at[0, key] = val\n",
    "\n",
    "# Predict\n",
    "log_price = model.predict(input_data)[0]\n",
    "price = np.exp(log_price)\n",
    "print(f\"Predicted Sale Price: ${price:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d9a2d2-3fa4-44d7-bcb2-b62514fc14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Raw log prediction:\", log_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae241625-35c6-4930-9e8a-6aa94fa7e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input shape:\", input_data.shape)\n",
    "print(\"Expected shape:\", len(columns))\n",
    "print(\"All columns match:\", all(input_data.columns == columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc43eca-7a40-41b8-878d-417787426a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
